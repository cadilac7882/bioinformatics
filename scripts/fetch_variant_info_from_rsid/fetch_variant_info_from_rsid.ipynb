{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "#from urllib3.exceptions import ConnectTimeoutError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esearch(rsid: str) -> Optional[bytes]:\n",
    "    \"\"\"\n",
    "    Fetch SNP XML data through ncbi e-fetch api\n",
    "    \"\"\"\n",
    "    logging.info(f\"Fetching SNP info for {rsid}\")\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"snp\",\n",
    "        \"id\": rsid,\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch {rsid}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spdi_to_vcf_field(spdi_string: str, max_retries=3) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Convert SPDI to VCF fields\n",
    "    \"\"\"\n",
    "    base_url = f\"https://api.ncbi.nlm.nih.gov/variation/v0/spdi/{spdi_string}/vcf_fields\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(base_url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json().get(\"data\")\n",
    "            if data:\n",
    "                return data\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Attempt {attempt + 1} failed for SPDI {spdi_string}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "    logging.error(f\"All retries failed for SPDI {spdi_string}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_esearch_xml(xml_data):\n",
    "    # Decode the byte string to a UTF-8 encoded string\n",
    "    xml_string = xml_data.decode(\"utf-8\")\n",
    "    \n",
    "    # Parse the XML string\n",
    "    root = ET.fromstring(xml_string)\n",
    "    \n",
    "    # Find required entities\n",
    "    snp_id = root.find(\"SNP_ID\").text\n",
    "    snp_class = root.find(\"SNP_CLASS\").text\n",
    "    acc2chr={root.find(\"ACC\").text:root.find(\"CHR\").text}\n",
    "    location_hg38 = int(root.find(\"CHRPOS\").text.split(':')[1])\n",
    "    location_hg19 = int(root.find(\"CHRPOS_PREV_ASSM\").text.split(':')[1])\n",
    "    variation_vcf_fields = [spdi_to_vcf_field(item) for item in root.find(\"SPDI\").text.split(',')]\n",
    "    \n",
    "    if None in variation_vcf_fields:\n",
    "        print(variation_vcf_fields)\n",
    "        logging.warning(f\"Skipping {snp_id} due to fetch SDPI failure.\")\n",
    "        return None \n",
    "    else:\n",
    "        variation_hg38 = [ f\"{acc2chr[var['chrom']]}:{var['pos']}:{var['ref']}:{var['alt']}\" for var in variation_vcf_fields if var]\n",
    "\n",
    "        if len(set([ var['pos'] for var in variation_vcf_fields]))>1:\n",
    "            print(snp_id)\n",
    "            \n",
    "        if variation_vcf_fields[0]['pos'] == location_hg38:\n",
    "            variation_hg19 = [ var.replace(str(location_hg38),str(location_hg19)) for var in variation_hg38]\n",
    "        else:\n",
    "            offset = location_hg38-variation_vcf_fields[0]['pos']\n",
    "            location_hg19_fix = location_hg19 - offset\n",
    "            location_hg38_fix = variation_vcf_fields[0]['pos']\n",
    "            variation_hg19 = [ var.replace(str(location_hg38_fix),str(location_hg19_fix)) for var in variation_hg38]\n",
    "        return {\n",
    "            \"snp_id\": snp_id,\n",
    "            \"snp_class\":snp_class,\n",
    "            \"variation_hg38\": variation_hg38,\n",
    "            \"variation_hg19\": variation_hg19\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_annotation=pd.read_csv(\"data/snplist.txt\",sep=\"\\t\",header=None)\n",
    "variant_annotation=variant_annotation.rename(columns={0:'Variant'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ignore snp without rs id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows without rsID\n",
    "uniq_rsid=variant_annotation[\"Variant\"][variant_annotation['Variant'].str.contains('^rs[0-9]+')].unique()\n",
    "print(f\"{len(uniq_rsid)} unique variants with rsID.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetch genomic position and alleles through E-search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list={}\n",
    "waiting_list=[id for id in uniq_rsid]\n",
    "fail_list=[]\n",
    "while len(waiting_list) > 0:\n",
    "    rs_id=waiting_list.pop()\n",
    "    xml_data = esearch(rs_id)\n",
    "    if xml_data:\n",
    "        parsed_data = parse_esearch_xml(xml_data)\n",
    "        if parsed_data:\n",
    "            result_list[rs_id]=parsed_data\n",
    "        else:\n",
    "            ## add rsIDs which failed from parsing xml back to waiting_list\n",
    "            print(f\"Failed to parse data for {rs_id}\")\n",
    "            waiting_list.append(rs_id)\n",
    "    else:\n",
    "        ## add the rsID which failed from e-searching back to fail_list\n",
    "        print(f\"No data received from esearch for {rs_id}\")\n",
    "        fail_list.append(rs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/result.json', 'w') as outfile:\n",
    "    json.dump(result_list, outfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rsid_dict={'rs_id':[],'variation_hg19':[],'variation_hg38':[]}\n",
    "for rsid,detail in result_list.items():\n",
    "    for index in range(len(detail['variation_hg19'])):\n",
    "        pos_rsid_dict['rs_id'].append(rsid)\n",
    "        pos_rsid_dict['variation_hg19'].append(detail['variation_hg19'][index])\n",
    "        pos_rsid_dict['variation_hg38'].append(detail['variation_hg38'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_df = pd.DataFrame.from_dict(pos_rsid_dict)\n",
    "variant_df.to_csv('data/result.tsv',sep=\"\\t\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
